{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModulesLayersModels",
      "provenance": [],
      "authorship_tag": "ABX9TyPDy/MOwjyL/NFL8kW5+AnO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW6bl1gdrrvR"
      },
      "source": [
        "To do machine learning in TensorFlow, you are likely to need to define, save, and restore a model.\r\n",
        "\r\n",
        "A model is, abstractly:\r\n",
        "\r\n",
        "A function that computes something on tensors (a forward pass)\r\n",
        "Some variables that can be updated in response to training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3ZBx7629K9v"
      },
      "source": [
        "**Defining models and layers**\r\n",
        "\r\n",
        "Most models are made of layers. Layers are functions with a known mathematical structure that can be reused and have trainable variables. In TensorFlow, most high-level implementations of layers and models, such as Keras or Sonnet, are built on the same foundational class: tf.Module.\r\n",
        "\r\n",
        "Here's an example of a very simple tf.Module that operates on a scalar tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMnYmpDqIRJK"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN8nTWD4HUcr",
        "outputId": "af63987f-5b1d-4ca2-ade7-2cbe466d21c0"
      },
      "source": [
        "class SimpleModule(tf.Module):\r\n",
        "  def __init__(self, name=None):\r\n",
        "    super().__init__(name=name)\r\n",
        "    self.a_variable = tf.Variable(5.0, name=\"train_me\")\r\n",
        "    self.non_trainable_variable = tf.Variable(5.0, trainable=False, name=\"do_not_train_me\")\r\n",
        "  def __call__(self, x):\r\n",
        "    return self.a_variable * x + self.non_trainable_variable\r\n",
        "\r\n",
        "simple_module = SimpleModule(name=\"simple\")\r\n",
        "\r\n",
        "simple_module(tf.constant(5.0))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oenhiyV3IOa2"
      },
      "source": [
        "Modules and, by extension, layers are deep-learning terminology for \"objects\": They have internal state, and methods that use that state.\r\n",
        "\r\n",
        "There is nothing special about __call__ except to act like a Python callable; you can invoke your models with whatever functions you wish.\r\n",
        "\r\n",
        "You can set the trainability of variables on and off for any reason, including freezing layers and variables during fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_y8buVoIYe7"
      },
      "source": [
        "By subclassing tf.Module, any tf.Variable or tf.Module instances assigned to this object's properties are automatically collected. This allows you to save and load variables, and also create collections oftf.Modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8bKInsCIXDY",
        "outputId": "079557a1-3b49-482b-9388-8620a97c6216"
      },
      "source": [
        "# All trainable variables\r\n",
        "print(\"trainable variables:\", simple_module.trainable_variables)\r\n",
        "# Every variable\r\n",
        "print(\"all variables:\", simple_module.variables)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable variables: (<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>,)\n",
            "all variables: (<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>, <tf.Variable 'do_not_train_me:0' shape=() dtype=float32, numpy=5.0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ERbSQ1Uvkh",
        "outputId": "23f3d884-d722-4f5b-b69f-6086dbd9492c"
      },
      "source": [
        "# Define dense(linear) layer\r\n",
        "class Dense(tf.Module):\r\n",
        "  def __init__(self, in_features, out_features, name=None):\r\n",
        "    super().__init__(name=name)\r\n",
        "    self.w = tf.Variable(\r\n",
        "      tf.random.normal([in_features, out_features]), name='w')\r\n",
        "    self.b = tf.Variable(tf.zeros([out_features]), name='b')\r\n",
        "  def __call__(self, x):\r\n",
        "    y = tf.matmul(x, self.w) + self.b\r\n",
        "    return tf.nn.relu(y)\r\n",
        "\r\n",
        "class SequentialModule(tf.Module):\r\n",
        "  def __init__(self, name=None):\r\n",
        "    super().__init__(name=name)\r\n",
        "\r\n",
        "    self.dense_1 = Dense(in_features=3, out_features=3)\r\n",
        "    self.dense_2 = Dense(in_features=3, out_features=2)\r\n",
        "\r\n",
        "  def __call__(self, x):\r\n",
        "    x = self.dense_1(x)\r\n",
        "    return self.dense_2(x)\r\n",
        "\r\n",
        "# You have made a model!\r\n",
        "my_model = SequentialModule(name=\"the_model\")\r\n",
        "\r\n",
        "# Call it, with random results\r\n",
        "print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model results: tf.Tensor([[0.        0.6576674]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jI3MqA3WmbR"
      },
      "source": [
        "tf.Module instances will automatically collect, recusively, any tf.Variable or tf.Module instances assigned to it. This allows you to manage collections oftf.Modules with a single model instance, and save and load whole models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OA5Tz-HWnuK",
        "outputId": "4c4957e2-5d4f-403b-9e75-f56d2692c474"
      },
      "source": [
        "print(\"Submodules:\", my_model.submodules)\r\n",
        "\r\n",
        "for var in my_model.variables:\r\n",
        "  print(var, \"\\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submodules: (<__main__.Dense object at 0x7fcdc3947668>, <__main__.Dense object at 0x7fcdc3947748>)\n",
            "<tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)> \n",
            "\n",
            "<tf.Variable 'w:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.1152038 ,  0.47963965,  0.34614968],\n",
            "       [ 0.17695947, -1.8753347 , -0.9213557 ],\n",
            "       [-1.7841964 ,  0.04245811,  0.86727023]], dtype=float32)> \n",
            "\n",
            "<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)> \n",
            "\n",
            "<tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
            "array([[ 0.03070423,  1.0520147 ],\n",
            "       [ 1.1122874 ,  0.7009342 ],\n",
            "       [-0.14330979,  1.1258953 ]], dtype=float32)> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHOSAV-LWsvq"
      },
      "source": [
        "**Create variables**\r\n",
        "\r\n",
        "By deferring variable creation to the first time the module is called with a specific input shape, you do not need specify the input size up front."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_BfsWv8Y0u2",
        "outputId": "2f54d747-6e25-4956-8857-f1323e467bb0"
      },
      "source": [
        "class FlexibleDenseModule(tf.Module):\r\n",
        "  # Note: No need for `in+features`\r\n",
        "  def __init__(self, out_features, name=None):\r\n",
        "    super().__init__(name=name)\r\n",
        "    self.is_built = False\r\n",
        "    self.out_features = out_features\r\n",
        "\r\n",
        "  def __call__(self, x):\r\n",
        "    # Create variables on first call.\r\n",
        "    if not self.is_built:\r\n",
        "      self.w = tf.Variable(\r\n",
        "        tf.random.normal([x.shape[-1], self.out_features]), name='w')\r\n",
        "      self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\r\n",
        "      self.is_built = True\r\n",
        "\r\n",
        "    y = tf.matmul(x, self.w) + self.b\r\n",
        "    return tf.nn.relu(y)\r\n",
        "\r\n",
        "# Used in a module\r\n",
        "class MySequentialModule(tf.Module):\r\n",
        "  def __init__(self, name=None):\r\n",
        "    super().__init__(name=name)\r\n",
        "\r\n",
        "    self.dense_1 = FlexibleDenseModule(out_features=3)\r\n",
        "    self.dense_2 = FlexibleDenseModule(out_features=2)\r\n",
        "\r\n",
        "  def __call__(self, x):\r\n",
        "    x = self.dense_1(x)\r\n",
        "    return self.dense_2(x)\r\n",
        "\r\n",
        "my_model = MySequentialModule(name=\"the_model\")\r\n",
        "print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model results: tf.Tensor([[1.2797499 3.927663 ]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K3yB2j8Y1IX"
      },
      "source": [
        "This flexibility is why TensorFlow layers often only need to specify the shape of their outputs, such as in tf.keras.layers.Dense, rather than both the input and output size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqt10ePoZFwz"
      },
      "source": [
        "**Saving weights**\r\n",
        "\r\n",
        "You can save a [tf.Module](https://www.tensorflow.org/api_docs/python/tf/Module) as both a [checkpoint](https://www.tensorflow.org/guide/checkpoint) and a [SavedModel](https://www.tensorflow.org/guide/saved_model).\r\n",
        "\r\n",
        "Checkpoints are just the weights (that is, the values of the set of variables inside the module and its submodules)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "P9BPB2x4ZU2D",
        "outputId": "739f7a8f-4172-4276-8c5a-10e9b30e1bd8"
      },
      "source": [
        "chkp_path = \"my_checkpoint\"\r\n",
        "checkpoint = tf.train.Checkpoint(model=my_model)\r\n",
        "checkpoint.write(chkp_path)\r\n",
        "checkpoint.write(chkp_path)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'my_checkpoint'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrCUtnmqZa1T",
        "outputId": "a7ffe3d6-ffea-406e-dc68-89d72c67bdaf"
      },
      "source": [
        "tf.train.list_variables(chkp_path)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n",
              " ('model/dense_1/b/.ATTRIBUTES/VARIABLE_VALUE', [3]),\n",
              " ('model/dense_1/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 3]),\n",
              " ('model/dense_2/b/.ATTRIBUTES/VARIABLE_VALUE', [2]),\n",
              " ('model/dense_2/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 2])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNEx2yzkZdeM",
        "outputId": "995fc15c-797d-4bc9-f61a-141d3e507e8f"
      },
      "source": [
        "new_model = MySequentialModule()\r\n",
        "new_checkpoint = tf.train.Checkpoint(model=new_model)\r\n",
        "new_checkpoint.restore(\"my_checkpoint\")\r\n",
        "\r\n",
        "# Should be the same result as above\r\n",
        "new_model(tf.constant([[2.0, 2.0, 2.0]]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1.2797499, 3.927663 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I9BOg3fZm0C"
      },
      "source": [
        "**Saving functions**\r\n",
        "\r\n",
        "TensorFlow can run models without the original Python objects, as seen in [TensorFlow Serving](https://www.tensorflow.org/tfx) and [TensorFlow Lite](https://www.tensorflow.org/lite) and even when you download a trained model from [TensorFlow Hub](https://www.tensorflow.org/hub).\r\n",
        "\r\n",
        "TensorFlow needs to know how to do the computations described in Python, but without the original code. To do this, you can make a graph, which is described in the previous guide.\r\n",
        "\r\n",
        "This graph contains operations, or ops, that implement the function.\r\n",
        "\r\n",
        "You can define a graph in the model above by adding the @tf.function decorator to indicate that this code should run as a graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e-vHXtYq6Wl"
      },
      "source": [
        "class MySequentialModule(tf.Module):\r\n",
        "  def __init__(self, name=None):\r\n",
        "    super().__init__(name=name)\r\n",
        "\r\n",
        "    self.dense_1 = Dense(in_features=3, out_features=3)\r\n",
        "    self.dense_2 = Dense(in_features=3, out_features=2)\r\n",
        "\r\n",
        "  @tf.function\r\n",
        "  def __call__(self, x):\r\n",
        "    x = self.dense_1(x)\r\n",
        "    return self.dense_2(x)\r\n",
        "\r\n",
        "# You have made a model with a graph!\r\n",
        "my_model = MySequentialModule(name=\"the_model\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw1C0yIFrLYs"
      },
      "source": [
        "**Visualize the graph**\r\n",
        "https://www.tensorflow.org/guide/intro_to_modules#saving_functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdoDYJyarVyE"
      },
      "source": [
        "**Creating a SavedModel**\r\n",
        "\r\n",
        "The recommended way of sharing completely trained models is to use SavedModel. SavedModel contains both a collection of functions and a collection of weights.\r\n",
        "\r\n",
        "You can save the model just made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_QclEgmrPM6",
        "outputId": "a82e16ba-f9ad-409e-86f3-4a40cb975e15"
      },
      "source": [
        "tf.saved_model.save(my_model, \"the_saved_model\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as __call__ while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as __call__ while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: the_saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: the_saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkth1V9yrVIc",
        "outputId": "3bc52bcc-cc8e-4298-ed52-509fbb2f7af3"
      },
      "source": [
        "# Inspect the SavedModel in the directory\r\n",
        "!ls -l the_saved_model"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 2 root root 4096 Jan  2 23:42 assets\n",
            "-rw-r--r-- 1 root root 9689 Jan  2 23:42 saved_model.pb\n",
            "drwxr-xr-x 2 root root 4096 Jan  2 23:42 variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQM_ceUtrn9o",
        "outputId": "c035087b-f961-485a-8dd3-974a6fc09bb5"
      },
      "source": [
        "# The variables/ directory contains a checkpoint of the variables \r\n",
        "!ls -l the_saved_model/variables"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "-rw-r--r-- 1 root root 408 Jan  2 23:42 variables.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root 356 Jan  2 23:42 variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2pGUXgDsI1N"
      },
      "source": [
        " load the model as new object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2bQjSdisLDz"
      },
      "source": [
        "new_model = tf.saved_model.load(\"the_saved_model\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNzw0YbRsO6O"
      },
      "source": [
        "new_model, created from loading a saved model, is an internal TensorFlow user object without any of the class knowledge. It is not of type SequentialModule."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOXvL-u2sPjG",
        "outputId": "efa5bf5a-571e-4e6b-91c2-1f585e688ec5"
      },
      "source": [
        "isinstance(new_model, SequentialModule)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_PumeyZsebU"
      },
      "source": [
        "## Keras models and layers\r\n",
        "\r\n",
        "Note that up until this point, there is no mention of Keras. You can build your own high-level API on top of `tf.Module`, and people have.  \r\n",
        "\r\n",
        "In this section, you will examine how Keras uses `tf.Module`.  A complete user guide to Keras models can be found in the [Keras guide](keras/sequential_model.ipynb).\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljOmdjBXwHfk"
      },
      "source": [
        "### Keras layers\r\n",
        "\r\n",
        "`tf.keras.layers.Layer` is the base class of all Keras layers, and it inherits from `tf.Module`.\r\n",
        "\r\n",
        "You can convert a module into a Keras layer just by swapping out the parent and then changing `__call__` to `call`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcI6yXDhsfDu"
      },
      "source": [
        "class MyDense(tf.keras.layers.Layer):\r\n",
        "  # Adding **kwargs to support base Keras layer arguments\r\n",
        "  def __init__(self, in_features, out_features, **kwargs):\r\n",
        "    super().__init__(**kwargs)\r\n",
        "\r\n",
        "    # This will soon move to the build step; see below\r\n",
        "    self.w = tf.Variable(\r\n",
        "      tf.random.normal([in_features, out_features]), name='w')\r\n",
        "    self.b = tf.Variable(tf.zeros([out_features]), name='b')\r\n",
        "  def call(self, x):\r\n",
        "    y = tf.matmul(x, self.w) + self.b\r\n",
        "    return tf.nn.relu(y)\r\n",
        "\r\n",
        "simple_layer = MyDense(name=\"simple\", in_features=3, out_features=3)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecB67ueuwNeI"
      },
      "source": [
        "Keras layers have their own `__call__` that does some bookkeeping described in the next section and then calls `call()`. You should notice no change in functionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdDH2kSVwOQ3",
        "outputId": "22147475-e549-40f7-e2b1-384e60dd6b35"
      },
      "source": [
        "simple_layer([[2.0, 2.0, 2.0]])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[1.3139296, 0.       , 0.       ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkU9TcFOwjUO"
      },
      "source": [
        "### The `build` step\r\n",
        "\r\n",
        "As noted, it's convenient in many cases to wait to create variables until you are sure of the input shape.\r\n",
        "\r\n",
        "Keras layers come with an extra lifecycle step that allows you more flexibility in how you define your layers. This is defined in the `build` function.\r\n",
        "\r\n",
        "`build` is called exactly once, and it is called with the shape of the input. It's usually used to create variables (weights).\r\n",
        "\r\n",
        "You can rewrite `MyDense` layer above be flexible to the size of its inputs:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4i9V0ZbwkIJ"
      },
      "source": [
        "class FlexibleDense(tf.keras.layers.Layer):\r\n",
        "  # Note the added `**kwargs`, as Keras supports many arguments\r\n",
        "  def __init__(self, out_features, **kwargs):\r\n",
        "    super().__init__(**kwargs)\r\n",
        "    self.out_features = out_features\r\n",
        "\r\n",
        "  def build(self, input_shape):  # Create the state of the layer (weights)\r\n",
        "    self.w = tf.Variable(\r\n",
        "      tf.random.normal([input_shape[-1], self.out_features]), name='w')\r\n",
        "    self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\r\n",
        "\r\n",
        "  def call(self, inputs):  # Defines the computation from inputs to outputs\r\n",
        "    return tf.matmul(inputs, self.w) + self.b\r\n",
        "\r\n",
        "# Create the instance of the layer\r\n",
        "flexible_dense = FlexibleDense(out_features=3)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChdTdK8Gwnwl"
      },
      "source": [
        "At this point, the model has not been built, so there are no variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CRmiGONwpEy",
        "outputId": "95d8a6f3-52ab-483e-fc58-11a6473f6670"
      },
      "source": [
        "flexible_dense.variables"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgQz7n59wtyc"
      },
      "source": [
        "Calling the function allocates appropriately-sized variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TH862SPwu8G",
        "outputId": "b4325857-958b-46b8-ff42-3c675e581298"
      },
      "source": [
        "# Call it, with predictably random results\r\n",
        "print(\"Model results:\", flexible_dense(tf.constant([[2.0, 2.0, 2.0], [3.0, 3.0, 3.0]])))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model results: tf.Tensor(\n",
            "[[-0.11512607  1.0850053  -1.4756911 ]\n",
            " [-0.17268932  1.6275079  -2.2135367 ]], shape=(2, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxIOO2-9wwSL",
        "outputId": "dd904890-a971-4d37-cc03-c911bad993cf"
      },
      "source": [
        "flexible_dense.variables"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'flexible_dense/w:0' shape=(3, 3) dtype=float32, numpy=\n",
              " array([[ 1.5051016 , -0.8767946 ,  0.14947516],\n",
              "        [-1.2274    ,  1.9344368 , -0.5905585 ],\n",
              "        [-0.33526465, -0.5151396 , -0.2967622 ]], dtype=float32)>,\n",
              " <tf.Variable 'flexible_dense/b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQxdH-2p0xBc"
      },
      "source": [
        "Since `build` is only called once, inputs will be rejected if the input shape is not compatible with the layer's variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk6YiL9X0yMP",
        "outputId": "dea14608-97f6-41eb-8bb2-80ec236bc306"
      },
      "source": [
        "try:\r\n",
        "  print(\"Model results:\", flexible_dense(tf.constant([[2.0, 2.0, 2.0, 2.0]])))\r\n",
        "except tf.errors.InvalidArgumentError as e:\r\n",
        "  print(\"Failed:\", e)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed: Matrix size-incompatible: In[0]: [1,4], In[1]: [3,3] [Op:MatMul]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9tA-JZV02jT"
      },
      "source": [
        "Keras layers have a lot more extra features including:\r\n",
        "\r\n",
        "* Optional losses\r\n",
        "* Support for metrics\r\n",
        "* Built-in support for an optional `training` argument to differentiate between training and inference use\r\n",
        "* `get_config` and `from_config` methods that allow you to accurately store configurations to allow model cloning in Python\r\n",
        "\r\n",
        "Read about them in the [full guide](./keras/custom_layers_and_models.ipynb) to custom layers and models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhaAwT4veqRL"
      },
      "source": [
        "### Keras models\r\n",
        "\r\n",
        "You can define your model as nested Keras layers.\r\n",
        "\r\n",
        "However, Keras also provides a full-featured model class called `tf.keras.Model`. It inherits from `tf.keras.layers.Layer`, so a Keras model can be used, nested, and saved in the same way as Keras layers. Keras models come with extra functionality that makes them easy to train, evaluate, load, save, and even train on multiple machines.\r\n",
        "\r\n",
        "You can define the `SequentialModule` from above with nearly identical code, again converting `__call__` to `call()` and changing the parent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aqnHVomer0Z",
        "outputId": "9b5a6f4d-0dfb-45b3-c779-054341cc5574"
      },
      "source": [
        "class MySequentialModel(tf.keras.Model):\r\n",
        "  def __init__(self, name=None, **kwargs):\r\n",
        "    super().__init__(**kwargs)\r\n",
        "\r\n",
        "    self.dense_1 = FlexibleDense(out_features=3)\r\n",
        "    self.dense_2 = FlexibleDense(out_features=2)\r\n",
        "  def call(self, x):\r\n",
        "    x = self.dense_1(x)\r\n",
        "    return self.dense_2(x)\r\n",
        "\r\n",
        "# You have made a Keras model!\r\n",
        "my_sequential_model = MySequentialModel(name=\"the_model\")\r\n",
        "\r\n",
        "# Call it on a tensor, with random results\r\n",
        "print(\"Model results:\", my_sequential_model(tf.constant([[2.0, 2.0, 2.0]])))\r\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model results: tf.Tensor([[ 0.38933146 -7.669828  ]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyu5GnAVfO7D"
      },
      "source": [
        "All the same features are available, including tracking variables and submodules.\r\n",
        "\r\n",
        "Note: To emphasize the note above, a raw `tf.Module` nested inside a Keras layer or model will not get its variables collected for training or saving.  Instead, nest Keras layers inside of Keras layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNM5wdvRfQR8",
        "outputId": "e7b2907a-16c4-47ed-8ad8-f66a8aeb1563"
      },
      "source": [
        "my_sequential_model.variables"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'my_sequential_model/flexible_dense_1/w:0' shape=(3, 3) dtype=float32, numpy=\n",
              " array([[ 0.22013463, -0.61087656,  0.5450411 ],\n",
              "        [ 0.6208449 ,  1.6311418 , -1.5644598 ],\n",
              "        [ 2.1502156 ,  1.0405567 , -0.4279506 ]], dtype=float32)>,\n",
              " <tf.Variable 'my_sequential_model/flexible_dense_1/b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'my_sequential_model/flexible_dense_2/w:0' shape=(3, 2) dtype=float32, numpy=\n",
              " array([[-0.5019968 , -1.4981178 ],\n",
              "        [-0.13849811, -0.46914455],\n",
              "        [-1.3691434 , -1.1144859 ]], dtype=float32)>,\n",
              " <tf.Variable 'my_sequential_model/flexible_dense_2/b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0oAtslVfSsW",
        "outputId": "6b557ce2-4e76-45aa-cc9d-6b261f6631d9"
      },
      "source": [
        "my_sequential_model.submodules"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<__main__.FlexibleDense at 0x7fcd857b2240>,\n",
              " <__main__.FlexibleDense at 0x7fcd857b2320>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGxZNXa2fVBy"
      },
      "source": [
        "Overriding `tf.keras.Model` is a very Pythonic approach to building TensorFlow models.  If you are migrating models from other frameworks, this can be very straightforward.\r\n",
        "\r\n",
        "If you are constructing models that are simple assemblages of existing layers and inputs, you can save time and space by using the [functional API](./keras/functional.ipynb), which comes with additional features around model reconstruction and architecture.\r\n",
        "\r\n",
        "Here is the same model with the functional API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C06gwv7yfXmt",
        "outputId": "4ffac8b5-703f-469f-db0d-3e1d45c12300"
      },
      "source": [
        "inputs = tf.keras.Input(shape=[3,])\r\n",
        "\r\n",
        "x = FlexibleDense(3)(inputs)\r\n",
        "x = FlexibleDense(2)(x)\r\n",
        "\r\n",
        "my_functional_model = tf.keras.Model(inputs=inputs, outputs=x)\r\n",
        "\r\n",
        "my_functional_model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 3)]               0         \n",
            "_________________________________________________________________\n",
            "flexible_dense_3 (FlexibleDe (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "flexible_dense_4 (FlexibleDe (None, 2)                 8         \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGt0TI5XfgSu",
        "outputId": "a3ecbb9a-de09-403a-eb46-cc546e607819"
      },
      "source": [
        "my_functional_model(tf.constant([[2.0, 2.0, 2.0]]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1.7660265, 2.8311346]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73cNz-3nfhyU"
      },
      "source": [
        "The major difference here is that the input shape is specified up front as part of the functional construction process. The `input_shape` argument in this case does not have to be completely specified; you can leave some dimensions as `None`.\r\n",
        "\r\n",
        "Note: You do not need to specify `input_shape` or an `InputLayer` in a subclassed model; these arguments and layers will be ignored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvxuFOvZfj80"
      },
      "source": [
        "## Saving Keras models\r\n",
        "\r\n",
        "Keras models can be checkpointed, and that will look the same as `tf.Module`.\r\n",
        "\r\n",
        "Keras models can also be saved with `tf.saved_models.save()`, as they are modules.  However, Keras models have convenience methods and other functionality:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkK77uKoflkt",
        "outputId": "e2f220fa-bfc1-41d1-bf73-986ac74b0363"
      },
      "source": [
        "my_sequential_model.save(\"exname_of_file\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: exname_of_file/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: exname_of_file/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU8yzmu6fm5i"
      },
      "source": [
        "Just as easily, they can be loaded back in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRArj7nyfpN-",
        "outputId": "dde62d76-73a9-41fa-940b-1e2724935ff3"
      },
      "source": [
        "reconstructed_model = tf.keras.models.load_model(\"exname_of_file\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPzBqV6KfsEa"
      },
      "source": [
        "Keras `SavedModels` also save metric, loss, and optimizer states.\r\n",
        "\r\n",
        "This reconstructed model can be used and will produce the same result when called on the same data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA2pcfKQft_N",
        "outputId": "5592883f-618b-4798-98bb-07b5bcc0b335"
      },
      "source": [
        "reconstructed_model(tf.constant([[2.0, 2.0, 2.0]]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.38933146, -7.669828  ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USEOMHUrf06A"
      },
      "source": [
        "There is more to know about saving and serialization of Keras models, including providing configuration methods for custom layers for feature support. Check out the [guide to saving and serialization](keras/save_and_serialize)."
      ]
    }
  ]
}