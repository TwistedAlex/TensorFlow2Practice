{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4KeBb9+wPzYZw/UyVCj/r"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkgPZKDgx5gX"
      },
      "source": [
        "Graphs and tf.functions ref: https://www.tensorflow.org/guide/intro_to_graphs\r\n",
        "\r\n",
        "TensorFlow running eagerly means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python. Eager TensorFlow takes advantage of GPUs, allowing you to place variables, tensors, and even operations on GPUs and TPUs. It is also easy to debug.\r\n",
        "\r\n",
        "For some users, you may never need or want to leave Python.\r\n",
        "\r\n",
        "However, running TensorFlow op-by-op in Python prevents a host of accelerations otherwise available. If you can extract tensor computations from Python, you can make them into a graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx7hwX8kAiku"
      },
      "source": [
        "**Graphs are data structures that contain a set of `tf.Operation` objects, which represent units of computation; and `tf.Tensor` objects, which represent the units of data that flow between operations.** They are defined in a `tf.Graph` context. Since these graphs are data structures, they can be saved, run, and restored all without the original Python code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYqD5tM_Kv5A"
      },
      "source": [
        "**Tracing graphs**\r\n",
        "\r\n",
        "The way you create a graph in TensorFlow is to use tf.function, either as a direct call or as a decorator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCltoSuWxIvE"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import timeit\r\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPuXwzNLK6fC",
        "outputId": "abe0315a-db0f-48d1-9b6a-536f1402cb04"
      },
      "source": [
        "# Define a Python function\r\n",
        "def function_to_get_faster(x, y, b):\r\n",
        "  x = tf.matmul(x, y)\r\n",
        "  x = x + b\r\n",
        "  return x\r\n",
        "\r\n",
        "# Create a `Function` object that contains a graph\r\n",
        "a_function_that_uses_a_graph = tf.function(function_to_get_faster)\r\n",
        "\r\n",
        "# Make some tensors\r\n",
        "x1 = tf.constant([[1.0, 2.0]])\r\n",
        "y1 = tf.constant([[2.0], [3.0]])\r\n",
        "b1 = tf.constant(4.0)\r\n",
        "\r\n",
        "# It just works!\r\n",
        "a_function_that_uses_a_graph(x1, y1, b1).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P4L6v_xM0B_"
      },
      "source": [
        "tf.function-ized functions are Python callables that work the same as their Python equivalents. They have a particular class (python.eager.def_function.Function), but to you they act just as the non-traced version.\r\n",
        "\r\n",
        "tf.function recursively traces any Python function it calls."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y6PS4o8M0ZO",
        "outputId": "bb413866-6929-455e-f719-93e62393a608"
      },
      "source": [
        "def inner_function(x, y, b):\r\n",
        "  x = tf.matmul(x, y)\r\n",
        "  x = x + b\r\n",
        "  return x\r\n",
        "\r\n",
        "# Use the decorator\r\n",
        "@tf.function\r\n",
        "def outer_function(x):\r\n",
        "  y = tf.constant([[2.0], [3.0]])\r\n",
        "  b = tf.constant(4.0)\r\n",
        "\r\n",
        "  return inner_function(x, y, b)\r\n",
        "\r\n",
        "# Note that the callable will create a graph that\r\n",
        "# includes inner_function() as well as outer_function()\r\n",
        "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDtJWgKuNgir"
      },
      "source": [
        "**Flow control and side effects**\r\n",
        "\r\n",
        "Flow control and loops are converted to TensorFlow via [tf.autograph](https://www.tensorflow.org/api_docs/python/tf/autograph) by default. Autograph uses a combination of methods, including standardizing loop constructs, unrolling, and [AST](https://docs.python.org/3/library/ast.html) manipulation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4sY8xr4NuxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28f186a-294a-40d4-a293-0e3843788898"
      },
      "source": [
        "def my_function(x):\r\n",
        "  if tf.reduce_sum(x) <= 1:\r\n",
        "    return x * x\r\n",
        "  else:\r\n",
        "    return x-1\r\n",
        "\r\n",
        "a_function = tf.function(my_function)\r\n",
        "\r\n",
        "print(\"First branch, with graph:\", a_function(tf.constant(1.0)).numpy())\r\n",
        "print(\"Second branch, with graph:\", a_function(tf.constant([5.0, 5.0])).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First branch, with graph: 1.0\n",
            "Second branch, with graph: [4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhFfNxPelDIf"
      },
      "source": [
        "You can directly call the Autograph conversion to see how Python is converted into TensorFlow ops. This is, mostly, unreadable, but you can see the transformation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSS80zFRlFB8",
        "outputId": "a2e3d7f4-d380-4e01-c33a-c70f088b031d"
      },
      "source": [
        "# Don't read the output too carefully.\r\n",
        "print(tf.autograph.to_code(my_function))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def tf__my_function(x):\n",
            "    with ag__.FunctionScope('my_function', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "\n",
            "        def get_state():\n",
            "            return (do_return, retval_)\n",
            "\n",
            "        def set_state(vars_):\n",
            "            nonlocal do_return, retval_\n",
            "            (do_return, retval_) = vars_\n",
            "\n",
            "        def if_body():\n",
            "            nonlocal do_return, retval_\n",
            "            try:\n",
            "                do_return = True\n",
            "                retval_ = (ag__.ld(x) * ag__.ld(x))\n",
            "            except:\n",
            "                do_return = False\n",
            "                raise\n",
            "\n",
            "        def else_body():\n",
            "            nonlocal do_return, retval_\n",
            "            try:\n",
            "                do_return = True\n",
            "                retval_ = (ag__.ld(x) - 1)\n",
            "            except:\n",
            "                do_return = False\n",
            "                raise\n",
            "        ag__.if_stmt((ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(x),), None, fscope) <= 1), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k-b8aovlHfI"
      },
      "source": [
        "Autograph automatically converts if-then clauses, loops, break, return, continue, and more.\r\n",
        "\r\n",
        "Most of the time, Autograph will work without special considerations. However, there are some caveats, and the [tf.function guide](https://www.tensorflow.org/guide/function) can help here, as well as the complete [autograph reference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WABzP4SZlsei"
      },
      "source": [
        "Seeing the speed up\r\n",
        "Just wrapping a tensor-using function in [tf.function](https://www.tensorflow.org/api_docs/python/tf/function) does not automatically speed up your code. For small functions called a few times on a single machine, the overhead of calling a graph or graph fragment may dominate runtime. Also, if most of the computation was already happening on an accelerator, such as stacks of GPU-heavy convolutions, the graph speedup won't be large.\r\n",
        "\r\n",
        "For complicated computations, graphs can provide a significant speedup. This is because graphs reduce the Python-to-device communication and perform some speedups.\r\n",
        "\r\n",
        "The speedup is most obvious when running many small layers, as in the example below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U92DlE9Hl4qu"
      },
      "source": [
        "# Create an oveerride model to classify pictures\r\n",
        "class SequentialModel(tf.keras.Model):\r\n",
        "  def __init__(self, **kwargs):\r\n",
        "    super(SequentialModel, self).__init__(**kwargs)\r\n",
        "    self.flatten = tf.keras.layers.Flatten(input_shape=(28, 28))\r\n",
        "    # Add a lot of small layers\r\n",
        "    num_layers = 100\r\n",
        "    self.my_layers = [tf.keras.layers.Dense(64, activation=\"relu\")\r\n",
        "                      for n in range(num_layers)]\r\n",
        "    self.dropout = tf.keras.layers.Dropout(0.2)\r\n",
        "    self.dense_2 = tf.keras.layers.Dense(10)\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    x = self.flatten(x)\r\n",
        "    for layer in self.my_layers:\r\n",
        "      x = layer(x)\r\n",
        "    x = self.dropout(x)\r\n",
        "    x = self.dense_2(x)\r\n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNgaLzRml7oC"
      },
      "source": [
        "input_data = tf.random.uniform([20, 28, 28])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UAVvJAOl8OA",
        "outputId": "d2ad774e-cf83-48dc-b2df-076a42f5ab5f"
      },
      "source": [
        "eager_model = SequentialModel()\r\n",
        "\r\n",
        "# Don't count the time for the initial build.\r\n",
        "eager_model(input_data)\r\n",
        "print(\"Eager time:\", timeit.timeit(lambda: eager_model(input_data), number=100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eager time: 1.7778153839999504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYTlo3i7mDh8",
        "outputId": "a5568bb3-a6ac-4498-829b-49caea3f460c"
      },
      "source": [
        "# Wrap the call method in a `tf.function`\r\n",
        "graph_model = SequentialModel()\r\n",
        "graph_model.call = tf.function(graph_model.call)\r\n",
        "\r\n",
        "# Don't count the time for the initial build and trace.\r\n",
        "graph_model(input_data)\r\n",
        "print(\"Graph time:\", timeit.timeit(lambda: graph_model(input_data), number=100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph time: 0.17238710800029367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKN_mvzjnE22"
      },
      "source": [
        "[Polymorphic Functions](https://www.tensorflow.org/guide/intro_to_graphs#polymorphic_functions)"
      ]
    }
  ]
}
