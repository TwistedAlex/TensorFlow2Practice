{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EAGER_EXE_TUTORIAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNp9wdoIbWu9sxWSPL37SEE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TwistedAlex/TensorFlow2Practice/blob/main/EAGER_EXE_TUTORIAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBgHaCxIeKX-"
      },
      "source": [
        "**Eager execution**\r\n",
        "Evaluate operations immediately, without building graphs: operations *return concrete values* instead of constructing a compuational graph to run later. \r\n",
        "  *An intuitive interface*: Structure your code naturally and use Python data structures. Quickly iterate on small models and small data.\r\n",
        "  *Easier debugging*: Call ops directly to inspect running models and test changes. Use standard Python debugging toools for immediate error report.\r\n",
        "  *Natural control flow*: Use Python control flow instead of graph control flow, simplifying the specification of dynamic models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jadZi_NfET-"
      },
      "source": [
        "**Setup and basic usage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYSr91h9fFHE"
      },
      "source": [
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "import cProfile\r\n",
        "tf.compat.v1.enable_eager_execution()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XAQxdWLjWDL",
        "outputId": "18a330e6-e731-4475-cad0-f8af79f29741"
      },
      "source": [
        "# Eager execution is enabled by default in TF2.0\r\n",
        "\r\n",
        "tf.executing_eagerly()\r\n",
        "# Run TF ops and the results will return immediately:\r\n",
        "x = [[2.]]\r\n",
        "m = tf.matmul(x, x)\r\n",
        "print(\"hello, {}\".format(m))\r\n",
        "a = tf.constant([[1, 2], [3, 4]])\r\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello, [[4.]]\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1RIAi5p95Pp"
      },
      "source": [
        "Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noyh6Fax96ei",
        "outputId": "43d504dc-a3a3-43f3-ff69-e54c78977f3b"
      },
      "source": [
        "b = tf.add(a, 1)\r\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVmLsK7_963i"
      },
      "source": [
        "Operator overloading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqnMdIA6-izf",
        "outputId": "b704a6e8-4a90-49d3-e681-2853c80837f3"
      },
      "source": [
        "print(a * b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 2  6]\n",
            " [12 20]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q27eIQ5k-thE"
      },
      "source": [
        "Use NumPy values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dw1DZfE-uVY",
        "outputId": "33e2732c-b4c7-4ea5-9dbb-d08ab95de365"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "c = np.multiply(a, b)\r\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  6]\n",
            " [12 20]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SyjI92w_Boh"
      },
      "source": [
        "Obtain numpy value from a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDGadXb3_ErT",
        "outputId": "c92b43f9-db41-4b32-ec92-df373c551222"
      },
      "source": [
        "print(a.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Je2GJFr_V0t"
      },
      "source": [
        "**Dynamic control flow**\r\n",
        "\r\n",
        "A major benefit of eager execution is that all the functionality of the host language is available while your model is executing. So, for example, it is easy to write fizzbuzz:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T2gO-_8_53C"
      },
      "source": [
        "def fizzbuzz(max_num):\r\n",
        "  counter = tf.constant(0)\r\n",
        "  max_num = tf.convert_to_tensor(max_num)\r\n",
        "  for num in range(1, max_num.numpy()+1):\r\n",
        "    num = tf.constant(num)\r\n",
        "    if int(num % 3) == 0 and int(num % 5) == 0:\r\n",
        "      print('FizzBuzz')\r\n",
        "    elif int(num % 3) == 0:\r\n",
        "      print('Fizz')\r\n",
        "    elif int(num % 5) == 0:\r\n",
        "      print('Buzz')\r\n",
        "    else:\r\n",
        "      print(num.numpy())\r\n",
        "    counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr8OK7BAABRQ"
      },
      "source": [
        "This has conditionals that depend on tensor values and it prints these values at runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGxXjvcx_88m",
        "outputId": "718cc0e8-81b7-431a-cf7e-5c8dab652aea"
      },
      "source": [
        "fizzbuzz(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "Fizz\n",
            "4\n",
            "Buzz\n",
            "Fizz\n",
            "7\n",
            "8\n",
            "Fizz\n",
            "Buzz\n",
            "11\n",
            "Fizz\n",
            "13\n",
            "14\n",
            "FizzBuzz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBKkprX7FiQI"
      },
      "source": [
        "**Eager training**\r\n",
        "\r\n",
        "Computing gradients\r\n",
        "\r\n",
        "**Automatic differentiation** is useful for implementing machine learning algorithms such as backpropagation for training neural networks. During eager execution, use tf.GradientTape to trace operations for computing gradients later.\r\n",
        "\r\n",
        "You can use [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) to train and/or compute gradients in eager. It is especially useful for complicated training loops.\r\n",
        "\r\n",
        "\r\n",
        "Args\r\n",
        "\r\n",
        "persistent: Boolean controlling whether a persistent gradient tape is created. False by default, which means at most one call can be made to the gradient() method on this object.\r\n",
        "\r\n",
        "watch_accessed_variables: Boolean controlling whether the tape will automatically watch any (trainable) variables accessed while the tape is active. Defaults to True meaning gradients can be requested from any result computed in the tape derived from reading a trainable Variable. If False users must explicitly watch any Variables they want to request gradients from.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_KPSMOkanMt",
        "outputId": "61689924-2eb5-4d64-cf9b-0c3d3b5b68df"
      },
      "source": [
        "x = tf.constant(3.0)\r\n",
        "with tf.GradientTape() as g:\r\n",
        "  g.watch(x)\r\n",
        "  y = x * x\r\n",
        "dy_dx = g.gradient(y, x)\r\n",
        "print(dy_dx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOUkEO3V0KUq"
      },
      "source": [
        "**Train a model**\r\n",
        "\r\n",
        "The following example creates a **multi-layer model** that **classifies** the standard MNIST handwritten digits. It demonstrates the optimizer and layer APIs to build trainable graphs in an eager execution environment.\r\n",
        "\r\n",
        "Trainable variables (created by tf.Variable or tf.compat.v1.get_variable, where trainable=True is default in both cases) are **automatically watched**. Tensors can be manually watched by invoking the watch method on this context manager."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yUA8EbJFkAr",
        "outputId": "91fbb7aa-1260-4692-aa72-4ed9648ea42f"
      },
      "source": [
        "# Fetch and format the mnist data\r\n",
        "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\r\n",
        "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\r\n",
        "   tf.cast(mnist_labels,tf.int64)))\r\n",
        "dataset = dataset.shuffle(1000).batch(32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwMsq1bn0h5V"
      },
      "source": [
        "# Build the model\r\n",
        "mnist_model = tf.keras.Sequential([\r\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\r\n",
        "                         input_shape=(None, None, 1)),\r\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\r\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "  tf.keras.layers.Dense(10)\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSF2Ir540tIK"
      },
      "source": [
        "Even without training, call the model and inspect the output in eager execution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLNNRTx10t24",
        "outputId": "d49c3d78-3a69-47b7-d815-c8bba1d57602"
      },
      "source": [
        "for images,labels in dataset.take(1):\r\n",
        "  print(\"Logits: \", mnist_model(images[0:1]).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logits:  [[-0.01716779 -0.01314864 -0.04200247 -0.02626937  0.00352457  0.03238138\n",
            "  -0.03156129  0.01748437 -0.0146309  -0.01443066]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhSaQt2bz6yg"
      },
      "source": [
        "While keras models have a builtin training loop (using the **fit**(next example) method), sometimes you need more **customization**(below). Here's an example, of a training loop implemented with eager:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io1QBgSI1NN2"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "\r\n",
        "# The loss function to be optimized\r\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "\r\n",
        "loss_history = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot3iUhnU1RRF"
      },
      "source": [
        "def train_step(images, labels):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    logits = mnist_model(images, training=True)\r\n",
        "\r\n",
        "    # Add asserts to check the shape of the output.\r\n",
        "    tf.debugging.assert_equal(logits.shape, (32, 10))\r\n",
        "\r\n",
        "    loss_value = loss_object(labels, logits)\r\n",
        "\r\n",
        "  loss_history.append(loss_value.numpy().mean())\r\n",
        "  # grads = d(loss)/d(param)\r\n",
        "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\r\n",
        "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ots2NuJ1XUD"
      },
      "source": [
        "def train(epochs):\r\n",
        "  for epoch in range(epochs):\r\n",
        "    for (batch, (images, labels)) in enumerate(dataset):\r\n",
        "      train_step(images, labels)\r\n",
        "    print ('Epoch {} finished'.format(epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk0-Uys11ZOK",
        "outputId": "8b40837a-807a-463a-ddd0-c6316c5b5eec"
      },
      "source": [
        "train(epochs = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 finished\n",
            "Epoch 1 finished\n",
            "Epoch 2 finished\n",
            "Epoch 3 finished\n",
            "Epoch 4 finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iXLvGY5P1eFH",
        "outputId": "a0038635-d34a-4ae9-9518-35d5dc3be3db"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(loss_history)\r\n",
        "plt.xlabel('Batch #')\r\n",
        "plt.ylabel('Loss [entropy]')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss [entropy]')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U31POQY4JuGH"
      },
      "source": [
        "**Variables and optimizers**\r\n",
        "[tf.Variable](https://www.tensorflow.org/api_docs/python/tf/Variable) objects store mutable [tf.Tensor](https://www.tensorflow.org/api_docs/python/tf/Tensor)-like values accessed during training to make automatic differentiation easier.\r\n",
        "\r\n",
        "The collections of variables can be encapsulated into layers or models, along with methods that operate on them. See Custom Keras layers and models for details. The main difference between layers and models is that models add methods like Model.fit, Model.evaluate, and Model.save.\r\n",
        "\r\n",
        "For example, the automatic differentiation example above can be rewritten:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Iw48WkdOyG"
      },
      "source": [
        "# Model class\r\n",
        "class Linear(tf.keras.Model):\r\n",
        "  def __init__(self):\r\n",
        "    super(Linear, self).__init__()\r\n",
        "    self.W = tf.Variable(5., name='weight')\r\n",
        "    self.B = tf.Variable(10., name='bias')\r\n",
        "  def call(self, inputs):\r\n",
        "    return inputs * self.W + self.B"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rnMxOUFdOgu"
      },
      "source": [
        "# A toy dataset of points around 3 * x + 2\r\n",
        "NUM_EXAMPLES = 2000\r\n",
        "training_inputs = tf.random.normal([NUM_EXAMPLES])\r\n",
        "noise = tf.random.normal([NUM_EXAMPLES])\r\n",
        "training_outputs = training_inputs * 3 + 2 + noise\r\n",
        "\r\n",
        "# The loss function to be optimized\r\n",
        "def loss(model, inputs, targets):\r\n",
        "  error = model(inputs) - targets\r\n",
        "  return tf.reduce_mean(tf.square(error))\r\n",
        "\r\n",
        "def grad(model, inputs, targets):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    loss_value = loss(model, inputs, targets)\r\n",
        "  return tape.gradient(loss_value, [model.W, model.B])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK2OIj7Enam6"
      },
      "source": [
        "\r\n",
        "\r\n",
        "1.   Create the model.\r\n",
        "2.   The Derivatives of a loss function with respect to model parameters.\r\n",
        "3.   A strategy for updating the variables based on the derivatives.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfdMMUp4dOO6",
        "outputId": "25e3c80e-2e86-46f3-f7e0-70c55a2f3c97"
      },
      "source": [
        "model = Linear()\r\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\r\n",
        "\r\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\r\n",
        "\r\n",
        "steps = 300\r\n",
        "for i in range(steps):\r\n",
        "  grads = grad(model, training_inputs, training_outputs)\r\n",
        "  optimizer.apply_gradients(zip(grads, [model.W, model.B]))\r\n",
        "  if i % 20 == 0:\r\n",
        "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial loss: 69.399\n",
            "Loss at step 000: 66.700\n",
            "Loss at step 020: 30.356\n",
            "Loss at step 040: 14.098\n",
            "Loss at step 060: 6.824\n",
            "Loss at step 080: 3.570\n",
            "Loss at step 100: 2.114\n",
            "Loss at step 120: 1.463\n",
            "Loss at step 140: 1.171\n",
            "Loss at step 160: 1.041\n",
            "Loss at step 180: 0.982\n",
            "Loss at step 200: 0.956\n",
            "Loss at step 220: 0.944\n",
            "Loss at step 240: 0.939\n",
            "Loss at step 260: 0.937\n",
            "Loss at step 280: 0.936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEkXF1cGn1k-",
        "outputId": "7265915e-f0a9-471a-ed21-ea792053c2d3"
      },
      "source": [
        "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final loss: 0.935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ooiw82In3RL",
        "outputId": "64f7862a-602c-4b75-b869-8f4e9718a0b8"
      },
      "source": [
        "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W = 2.9885663986206055, B = 1.9746339321136475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05mRnwlyoLKK",
        "outputId": "cfa6e937-a220-43e4-96e6-4b79043cc052"
      },
      "source": [
        "print(model.call(3))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(10.940333, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi0DjzgQomDS"
      },
      "source": [
        "**Object-based saving**\r\n",
        "\r\n",
        "A tf.keras.Model includes a convenient save_weights method allowing you to easily create a checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frqml4NaopEk"
      },
      "source": [
        "model.save_weights('weights')\r\n",
        "status = model.load_weights('weights')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE6vB5Z6o038"
      },
      "source": [
        "Using [tf.train.Checkpoint](https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint) you can take full control over this process.\r\n",
        "\r\n",
        "This section is an abbreviated version of the guide to training [checkpoints](https://www.tensorflow.org/guide/checkpoint)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvuY6Uq8pt5Y"
      },
      "source": [
        "x = tf.Variable(10.)\r\n",
        "checkpoint = tf.train.Checkpoint(x=x)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6xdttHVUpuXH",
        "outputId": "2f87901f-76f9-45d2-cbe0-8fbd54562c23"
      },
      "source": [
        "x.assign(2.)   # Assign a new value to the variables and save.\r\n",
        "checkpoint_path = './ckpt/'\r\n",
        "checkpoint.save('./ckpt/')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./ckpt/-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XFF2ZYFp9N7",
        "outputId": "51ad0142-a459-41fc-8c8f-a071b32e60f0"
      },
      "source": [
        "x.assign(11.)  # Change the variable after saving.\r\n",
        "\r\n",
        "# Restore values from the checkpoint\r\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\r\n",
        "\r\n",
        "print(x)  # => 2.0"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcSsk5w6qBgL"
      },
      "source": [
        "To save and load models, tf.train.Checkpoint stores the internal state of objects, without requiring hidden variables. To record the state of a model, an optimizer, and a global step, pass them to a tf.train.Checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdGPldqEqDr3",
        "outputId": "fdc9123c-3be9-4ff9-fa1f-4bd67c403c82"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\r\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "  tf.keras.layers.Dense(10)\r\n",
        "])\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
        "checkpoint_dir = 'path/to/model_dir'\r\n",
        "if not os.path.exists(checkpoint_dir):\r\n",
        "  os.makedirs(checkpoint_dir)\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
        "root = tf.train.Checkpoint(optimizer=optimizer,\r\n",
        "                           model=model)\r\n",
        "\r\n",
        "root.save(checkpoint_prefix)\r\n",
        "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f11103e2ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXxO5ZbTqKN4"
      },
      "source": [
        "**Object-oriented metrics**\r\n",
        "\r\n",
        "tf.keras.metrics are stored as objects. Update a metric by passing the new data to the callable, and retrieve the result using the tf.keras.metrics.result method, for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jav1ZfD_qTGS",
        "outputId": "742c9d37-0e06-40eb-baac-cf6d8bebf74d"
      },
      "source": [
        "m = tf.keras.metrics.Mean(\"loss\")\r\n",
        "m(0)\r\n",
        "m(5)\r\n",
        "m.result()  # => 2.5\r\n",
        "m([8, 9])\r\n",
        "m.result()  # => 5.5"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=5.5>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyTVG3cgqgiY"
      },
      "source": [
        "**Summaries and TensorBoard**\r\n",
        "\r\n",
        "[TensorBoard](https://www.tensorflow.org/tensorboard) is a visualization tool for understanding, debugging and optimizing the model training process. It uses summary events that are written while executing the program.\r\n",
        "\r\n",
        "You can use [tf.summary](https://www.tensorflow.org/api_docs/python/tf/summary) to record summaries of variable in eager execution. For example, to record summaries of loss once every 100 training steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTTO005RrBnA"
      },
      "source": [
        "logdir = \"./tb/\"\r\n",
        "writer = tf.summary.create_file_writer(logdir)\r\n",
        "\r\n",
        "steps = 1000\r\n",
        "with writer.as_default():  # or call writer.set_as_default() before the loop.\r\n",
        "  for i in range(steps):\r\n",
        "    step = i + 1\r\n",
        "    # Calculate loss with your real train function.\r\n",
        "    loss = 1 - 0.001 * step\r\n",
        "    if step % 100 == 0:\r\n",
        "      tf.summary.scalar('loss', loss, step=step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhRPmfy8raAx"
      },
      "source": [
        "**Advanced automatic differentiation topics**\r\n",
        "\r\n",
        "Dynamic models\r\n",
        "\r\n",
        "tf.GradientTape can also be used in dynamic models. This example for a backtracking line search algorithm looks like normal NumPy code, except there are gradients and is differentiable, despite the complex control flow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRhMCohwr0hU"
      },
      "source": [
        "def line_search_step(fn, init_x, rate=1.0):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    # Variables are automatically tracked.\r\n",
        "    # But to calculate a gradient from a tensor, you must `watch` it.\r\n",
        "    tape.watch(init_x)\r\n",
        "    value = fn(init_x)\r\n",
        "  grad = tape.gradient(value, init_x)\r\n",
        "  grad_norm = tf.reduce_sum(grad * grad)\r\n",
        "  init_value = value\r\n",
        "  while value > init_value - rate * grad_norm:\r\n",
        "    x = init_x - rate * grad\r\n",
        "    value = fn(x)\r\n",
        "    rate /= 2.0\r\n",
        "  return x, value"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvUqFy4IvBh7"
      },
      "source": [
        "Custom gradients\r\n",
        "\r\n",
        "Custom gradients are an easy way to override gradients. Within the forward function, define the gradient with respect to the inputs, outputs, or intermediate results. For example, here's an easy way to clip the norm of the gradients in the backward pass:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHtVuwcovDe-"
      },
      "source": [
        "@tf.custom_gradient\r\n",
        "def clip_gradient_by_norm(x, norm):\r\n",
        "  y = tf.identity(x)\r\n",
        "  def grad_fn(dresult):\r\n",
        "    return [tf.clip_by_norm(dresult, norm), None]\r\n",
        "  return y, grad_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jISxdNnYvPzu"
      },
      "source": [
        "Custom gradients are commonly used to provide a numerically stable gradient for a sequence of operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uokAg67IvO3n"
      },
      "source": [
        "def log1pexp(x):\r\n",
        "  return tf.math.log(1 + tf.exp(x))\r\n",
        "\r\n",
        "def grad_log1pexp(x):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    tape.watch(x)\r\n",
        "    value = log1pexp(x)\r\n",
        "    # Grad = d(value)/d(x)\r\n",
        "  return tape.gradient(value, x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vwhElEDvVcq",
        "outputId": "f4bf28af-dccc-4809-a6fd-8072d6434683"
      },
      "source": [
        "# The gradient computation works fine at x = 0.\r\n",
        "grad_log1pexp(tf.constant(0.)).numpy()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKkki0qfvWvI",
        "outputId": "2cad7fd1-58c9-42d9-fc31-f95013006636"
      },
      "source": [
        "# However, x = 100 fails because of numerical instability.\r\n",
        "grad_log1pexp(tf.constant(100.)).numpy()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7QNR7E5945i",
        "outputId": "bd4936fa-2efe-4b09-ee3d-33c0e3f213ff"
      },
      "source": [
        "print(tf.exp(100.).numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGDWrhL5vYg6"
      },
      "source": [
        "Here, the log1pexp function can be analytically simplified with a custom gradient. The implementation below reuses the value for tf.exp(x) that is computed during the forward passmaking it more efficient by eliminating redundant calculations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tGKyC5WvZyf"
      },
      "source": [
        "@tf.custom_gradient\r\n",
        "def log1pexp(x):\r\n",
        "  e = tf.exp(x)\r\n",
        "  def grad(dy):\r\n",
        "    return dy * (1 - 1 / (1 + e))\r\n",
        "  return tf.math.log(1 + e), grad\r\n",
        "\r\n",
        "def grad_log1pexp(x):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    tape.watch(x)\r\n",
        "    value = log1pexp(x)\r\n",
        "  return tape.gradient(value, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqCeVgCMva9w"
      },
      "source": [
        "# As before, the gradient computation works fine at x = 0.\r\n",
        "grad_log1pexp(tf.constant(0.)).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptWxUfNxvcHP"
      },
      "source": [
        "# And the gradient computation also works at x = 100.\r\n",
        "grad_log1pexp(tf.constant(100.)).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgDQPRb5vU1o"
      },
      "source": [
        "**Performance**\r\n",
        "\r\n",
        "Computation is automatically offloaded to GPUs during eager execution. If you want control over where a computation runs you can enclose it in a tf.device('/gpu:0') block (or the CPU equivalent):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CkDCIEA_KLU",
        "outputId": "5a5b7ce0-9d10-4520-c9ba-c91cf0c62930"
      },
      "source": [
        "import time\r\n",
        "\r\n",
        "def measure(x, steps):\r\n",
        "  # TensorFlow initializes a GPU the first time it's used, exclude from timing.\r\n",
        "  tf.matmul(x, x)\r\n",
        "  start = time.time()\r\n",
        "  for i in range(steps):\r\n",
        "    x = tf.matmul(x, x)\r\n",
        "  # tf.matmul can return before completing the matrix multiplication\r\n",
        "  # (e.g., can return after enqueing the operation on a CUDA stream).\r\n",
        "  # The x.numpy() call below will ensure that all enqueued operations\r\n",
        "  # have completed (and will also copy the result to host memory,\r\n",
        "  # so we're including a little more than just the matmul operation\r\n",
        "  # time).\r\n",
        "  _ = x.numpy()\r\n",
        "  end = time.time()\r\n",
        "  return end - start\r\n",
        "\r\n",
        "shape = (1000, 1000)\r\n",
        "steps = 200\r\n",
        "print(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\r\n",
        "\r\n",
        "# Run on CPU:\r\n",
        "with tf.device(\"/cpu:0\"):\r\n",
        "  print(\"CPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\r\n",
        "\r\n",
        "# Run on GPU, if available:\r\n",
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\r\n",
        "  with tf.device(\"/gpu:0\"):\r\n",
        "    print(\"GPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\r\n",
        "else:\r\n",
        "  print(\"GPU: not found\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to multiply a (1000, 1000) matrix by itself 200 times:\n",
            "CPU: 6.392500400543213 secs\n",
            "GPU: not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGSr_DfZ_ex7"
      },
      "source": [
        "A tf.Tensor object can be copied to a different device to execute its operations:\r\n",
        "\r\n",
        "#TODO CHECK AVAILABILITY IN CURRENT VERSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCyXZe_N_fuT"
      },
      "source": [
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\r\n",
        "  x = tf.random.normal([10, 10])\r\n",
        "\r\n",
        "  x_gpu0 = x.gpu()\r\n",
        "  x_cpu = x.cpu()\r\n",
        "\r\n",
        "  _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU\r\n",
        "  _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI2adrV0mn7Y"
      },
      "source": [
        "Disable eager execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFZvyYaolywK",
        "outputId": "a27e995f-0a21-4e9a-b3a4-8ffca0d2e4f2"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\r\n",
        "a = tf.constant([[1, 2], [3, 4]])\r\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const:0\", shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghyt0LWxl1bY",
        "outputId": "c223e361-78ab-4875-b50a-aaae388b1dd7"
      },
      "source": [
        "b = tf.add(a, 1)\r\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Add:0\", shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_OVp02V-xi5"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "c = np.multiply(a, b)\r\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}